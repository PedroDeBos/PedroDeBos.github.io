<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Random Forest | Portfolio Pedro de Bos" />
<meta property="og:type" content="book" />







<meta name="description" content="Random Forest | Portfolio Pedro de Bos">

<title>Random Forest | Portfolio Pedro de Bos</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.23/datatables.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<!--bookdown:toc:end-->
<!--bookdown:toc:start-->
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="random-forest" class="section level1">
<h1>Random Forest</h1>
<body id="start">
<div class="topnav">
<p><a href='index.html#Frontpage'>Frontpage</a>
<a href='data-visualisation.html#data-visualisation'>Data visualisation</a>
<a href='parametized-data-germany.html#parametized-data'>Parametizing data</a>
<a href='directory-structure.html#directory-structure'>Directory structure</a>
<a href='creating-a-r-package.html#creating-a-r-package'>R-package</a>
<a href='sql.html#SQL'>SQL</a>
<a href='bibliography-using-zotero.html#Bibliography using Zotero'>Zotero</a>
<a href='open-reproductibility-analysis.html#open-reproductibility-analysis'>Reproductibility</a>
<a href='future-endeavours.html#future-endeavours'>Future endeavours</a>
<a href='free-research-project-index.html#free-research-project'> Free research (Machine learning)</a>
<a href='cv.html#cv'>CV</a>
<a href='bibliography.html#bibliography'>Bibliography</a></p>
</div>
<p> </p>
<p>The random forest method works via decision tree classification: a model in which information on nodes. The reference forms a giant “tree” consisting of multiple branching paths, connected by nodes. These nodes contain information which of the branches a individual datapoint should go across. Data goes down the tree untill it no longer has any nodes on the tree or information about itself anymore.</p>
<p>This model, while simple, has very low predictive power. Random Forest works on the same principle as decision tree classification, but instead of taking áll datapoints and áll variables, it takes a random selection of them and performs the tree. It then repeats this process for an X amount of times, and finally combines the results of all different decision trees into a single tree. By doing this, it greatly increases its predictive power, and decreases it’s bias.</p>
<p>Now, we’ll perform a randomForest analysis in R. Data has been aquired from <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/car/">an archive of a UCI website</a> <span class="citation">(<a href="#ref-duaUCIMachineLearning2017" role="doc-biblioref">Dua and Graff 2017</a>)</span></p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="random-forest.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb106-2"><a href="random-forest.html#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="random-forest.html#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Reading the data</span></span>
<span id="cb106-4"><a href="random-forest.html#cb106-4" aria-hidden="true" tabindex="-1"></a>car_data<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;data.raw/car.data&quot;</span>, <span class="at">header=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>First, let’s take a look at the data: according too the metadata-file given with it, the different values mean:</p>
<ul>
<li>V1: Buying price</li>
<li>V2: Selling price</li>
<li>V3: Amount of doors</li>
<li>V4: Amount of people who fit in the car</li>
<li>V5: Size of the luggage boot</li>
<li>V6: Estimated safety of the car</li>
<li>V7: Overal car acceptibility</li>
</ul>
<p>All of these are set up like factors: With levels like vhigh, high, med, low, etc. Because of this, we’ll give them all a appropriate name and transform them into a factor.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="random-forest.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(car_data)<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="st">&quot;BuyingPrice&quot;</span>, <span class="st">&quot;Maintenance&quot;</span>, <span class="st">&quot;NumDoors&quot;</span>, <span class="st">&quot;NumPersons&quot;</span>, <span class="st">&quot;BootSpace&quot;</span>, <span class="st">&quot;Safety&quot;</span>, <span class="st">&quot;Condition&quot;</span>)</span>
<span id="cb107-2"><a href="random-forest.html#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="random-forest.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Changing &quot;character&quot; data into factor data for all data sets</span></span>
<span id="cb107-4"><a href="random-forest.html#cb107-4" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>BuyingPrice<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>BuyingPrice)</span>
<span id="cb107-5"><a href="random-forest.html#cb107-5" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>Maintenance<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>Maintenance)</span>
<span id="cb107-6"><a href="random-forest.html#cb107-6" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>NumDoors<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>NumDoors)</span>
<span id="cb107-7"><a href="random-forest.html#cb107-7" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>NumPersons<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>NumPersons)</span>
<span id="cb107-8"><a href="random-forest.html#cb107-8" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>BootSpace<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>BootSpace)</span>
<span id="cb107-9"><a href="random-forest.html#cb107-9" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>Safety<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>Safety)</span>
<span id="cb107-10"><a href="random-forest.html#cb107-10" aria-hidden="true" tabindex="-1"></a>car_data<span class="sc">$</span>Condition<span class="ot">&lt;-</span><span class="fu">factor</span>(car_data<span class="sc">$</span>Condition)</span>
<span id="cb107-11"><a href="random-forest.html#cb107-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-12"><a href="random-forest.html#cb107-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-13"><a href="random-forest.html#cb107-13" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">summary</span>(car_data))</span></code></pre></div>
<table>
<colgroup>
<col width="3%" />
<col width="15%" />
<col width="15%" />
<col width="12%" />
<col width="14%" />
<col width="12%" />
<col width="11%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">BuyingPrice</th>
<th align="left">Maintenance</th>
<th align="left">NumDoors</th>
<th align="left">NumPersons</th>
<th align="left">BootSpace</th>
<th align="left">Safety</th>
<th align="left">Condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">high :432</td>
<td align="left">high :432</td>
<td align="left">2 :432</td>
<td align="left">2 :576</td>
<td align="left">big :576</td>
<td align="left">high:576</td>
<td align="left">acc : 384</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">low :432</td>
<td align="left">low :432</td>
<td align="left">3 :432</td>
<td align="left">4 :576</td>
<td align="left">med :576</td>
<td align="left">low :576</td>
<td align="left">good : 69</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">med :432</td>
<td align="left">med :432</td>
<td align="left">4 :432</td>
<td align="left">more:576</td>
<td align="left">small:576</td>
<td align="left">med :576</td>
<td align="left">unacc:1210</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vhigh:432</td>
<td align="left">vhigh:432</td>
<td align="left">5more:432</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">vgood: 65</td>
</tr>
</tbody>
</table>
<p>According the summary, we can see that Buying price - Safety are all equallty spread, with Condition being the only factor where the 4 different levels have different amounts of expression. Because of this. We’ll use this condition as condition for our machine learning algorythm.</p>
<p>As is usual for machine learning, we’ll split the data into a training-set and a testing-set.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="random-forest.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb108-2"><a href="random-forest.html#cb108-2" aria-hidden="true" tabindex="-1"></a>partition<span class="ot">&lt;-</span><span class="fu">createDataPartition</span>(car_data<span class="sc">$</span>Condition, <span class="at">p=</span><span class="fl">0.75</span>, <span class="at">list=</span><span class="cn">FALSE</span>)</span>
<span id="cb108-3"><a href="random-forest.html#cb108-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-4"><a href="random-forest.html#cb108-4" aria-hidden="true" tabindex="-1"></a>car_train<span class="ot">&lt;-</span>car_data[partition,]</span>
<span id="cb108-5"><a href="random-forest.html#cb108-5" aria-hidden="true" tabindex="-1"></a>car_test<span class="ot">&lt;-</span>car_data[<span class="sc">-</span>partition,]</span>
<span id="cb108-6"><a href="random-forest.html#cb108-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">summary</span>(car_train))</span></code></pre></div>
<table>
<colgroup>
<col width="3%" />
<col width="15%" />
<col width="15%" />
<col width="12%" />
<col width="14%" />
<col width="12%" />
<col width="11%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">BuyingPrice</th>
<th align="left">Maintenance</th>
<th align="left">NumDoors</th>
<th align="left">NumPersons</th>
<th align="left">BootSpace</th>
<th align="left">Safety</th>
<th align="left">Condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">high :321</td>
<td align="left">high :331</td>
<td align="left">2 :329</td>
<td align="left">2 :431</td>
<td align="left">big :433</td>
<td align="left">high:431</td>
<td align="left">acc :288</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">low :326</td>
<td align="left">low :322</td>
<td align="left">3 :328</td>
<td align="left">4 :445</td>
<td align="left">med :435</td>
<td align="left">low :416</td>
<td align="left">good : 52</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">med :327</td>
<td align="left">med :326</td>
<td align="left">4 :321</td>
<td align="left">more:421</td>
<td align="left">small:429</td>
<td align="left">med :450</td>
<td align="left">unacc:908</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vhigh:323</td>
<td align="left">vhigh:318</td>
<td align="left">5more:319</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">vgood: 49</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="random-forest.html#cb109-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">summary</span>(car_test))</span></code></pre></div>
<table>
<colgroup>
<col width="3%" />
<col width="15%" />
<col width="15%" />
<col width="12%" />
<col width="14%" />
<col width="12%" />
<col width="11%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">BuyingPrice</th>
<th align="left">Maintenance</th>
<th align="left">NumDoors</th>
<th align="left">NumPersons</th>
<th align="left">BootSpace</th>
<th align="left">Safety</th>
<th align="left">Condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">high :111</td>
<td align="left">high :101</td>
<td align="left">2 :103</td>
<td align="left">2 :145</td>
<td align="left">big :143</td>
<td align="left">high:145</td>
<td align="left">acc : 96</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">low :106</td>
<td align="left">low :110</td>
<td align="left">3 :104</td>
<td align="left">4 :131</td>
<td align="left">med :141</td>
<td align="left">low :160</td>
<td align="left">good : 17</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">med :105</td>
<td align="left">med :106</td>
<td align="left">4 :111</td>
<td align="left">more:155</td>
<td align="left">small:147</td>
<td align="left">med :126</td>
<td align="left">unacc:302</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vhigh:109</td>
<td align="left">vhigh:114</td>
<td align="left">5more:113</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">vgood: 16</td>
</tr>
</tbody>
</table>
<p>Now, with the training data properly separated, we’ll create a random forest model to determine the “condition” of the car data.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="random-forest.html#cb110-1" aria-hidden="true" tabindex="-1"></a>Model1<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Condition <span class="sc">~</span> ., <span class="at">data =</span> car_train, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb110-2"><a href="random-forest.html#cb110-2" aria-hidden="true" tabindex="-1"></a>Model1</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Condition ~ ., data = car_train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 3.55%
## Confusion matrix:
##       acc good unacc vgood class.error
## acc   282    1     5     0  0.02083333
## good    7   40     0     5  0.23076923
## unacc  16    2   890     0  0.01982379
## vgood  10    0     0    39  0.20408163</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="random-forest.html#cb112-1" aria-hidden="true" tabindex="-1"></a>predModel1<span class="ot">&lt;-</span><span class="fu">predict</span>(Model1, car_test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb112-2"><a href="random-forest.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(predModel1, car_test[,<span class="dv">7</span>])</span></code></pre></div>
<pre><code>##           
## predModel1 acc good unacc vgood
##      acc    93    2     3     3
##      good    0   14     0     0
##      unacc   3    0   299     0
##      vgood   0    1     0    13</code></pre>
<p>It’s as easy as that, we’ve officially created a randomForest learning algorythm in R! However, as with all machine learning algorythms, there’s still much to be tweaked in order to create a optimal algorythm. For example, we can modify the “mtry” and the “ntree”, two important variables in randomForest models.</p>
<p>As said before, randomForest uses the same principle as decision tree classification, only moddified by randomness and repeating the process a whole lot. mtry and ntree change the randomness of the program: “Mtry” determines how many informationpoints are used for every “node” a sample has to go past to continue down the identification tree. “Ntree” determines the amount of samples used for every random decision tree that’s made. By modifying these values in the creation of the model, we can get a different outcome:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="random-forest.html#cb114-1" aria-hidden="true" tabindex="-1"></a>Model2<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Condition <span class="sc">~</span> ., <span class="at">data=</span> car_train, <span class="at">ntree =</span> <span class="dv">500</span>, <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb114-2"><a href="random-forest.html#cb114-2" aria-hidden="true" tabindex="-1"></a>Model2</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Condition ~ ., data = car_train, ntree = 500,      mtry = 6, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 1.93%
## Confusion matrix:
##       acc good unacc vgood class.error
## acc   279    2     5     2  0.03125000
## good    2   50     0     0  0.03846154
## unacc  11    2   895     0  0.01431718
## vgood   1    0     0    48  0.02040816</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="random-forest.html#cb116-1" aria-hidden="true" tabindex="-1"></a>predModel2<span class="ot">&lt;-</span><span class="fu">predict</span>(Model2, car_test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb116-2"><a href="random-forest.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(predModel2, car_test<span class="sc">$</span>Condition)</span></code></pre></div>
<pre><code>##           
## predModel2 acc good unacc vgood
##      acc    91    1     1     0
##      good    2   16     0     0
##      unacc   3    0   301     0
##      vgood   0    0     0    16</code></pre>
<p>By increasing the mtry to 6 and setting the ntree to 500, we’ve increased the accuracy of our randomForest program. In order to get a detailed breakdown of whether Model 2 is better than Model 1, randomForest has two built-in functions called “importance” and “varImPlot”, which we’ll use on both models. We can also use the previous “confusionMatrix” to determine the accuracy</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="random-forest.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(Model1)</span></code></pre></div>
<pre><code>##                    acc       good      unacc      vgood MeanDecreaseAccuracy MeanDecreaseGini
## BuyingPrice  78.399893 40.6308337  62.861221 42.2281098           95.8290633         74.87927
## Maintenance  67.355170 39.8392362  46.336262 22.5572462           77.2186362         69.58717
## NumDoors     -2.170164 -0.9618957   1.819644 -0.4356103           -0.9882937         25.74268
## NumPersons   96.826502 28.3889395 124.765116 30.3347994          137.8254416        130.14305
## BootSpace    36.402520 23.6975470  42.442509 29.7169898           57.5485447         43.43290
## Safety      108.208164 43.3309064 131.811220 50.3694061          147.8153155        156.68554</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="random-forest.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(Model2)</span></code></pre></div>
<pre><code>##                   acc     good     unacc     vgood MeanDecreaseAccuracy MeanDecreaseGini
## BuyingPrice 169.47350 82.88810 111.79003  84.85052            211.20099         72.26247
## Maintenance 143.46414 78.43680 100.59932  50.82836            183.66137        101.94398
## NumDoors     36.84444 23.27634  43.95292  21.77875             60.99641         37.10614
## NumPersons  152.75017 56.42781 202.29261  57.95641            235.81146        117.05621
## BootSpace    89.80659 62.26000  88.13393  62.47436            138.56693         85.70045
## Safety      182.36283 98.65670 193.75459 102.59541            275.01957        177.77858</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="random-forest.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(Model1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="random-forest.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(Model2)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-60-2.png" width="672" /></p>
<p>In these plots, the “MeanDecreaseAccuracy” expresses how much accuracy the model loses when it does <em>not</em> consider the given variable, MeanDecreaseGini expresses measures how important that variable is for the homogeneity of the model. The higher the MeanDecreaseAccuracy/Gini, the more important it is for the model. Based on the significantly higher MeanDecreaseAccuracy in model 2 in comparisson to model 1, we can state that model 2 is indeed more accurate than model 1. Furthermore, the confusionMatrix for model 2 gives a higher accuracy than model 1.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="random-forest.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(predModel1, car_test[,<span class="dv">7</span>])</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction acc good unacc vgood
##      acc    93    2     3     3
##      good    0   14     0     0
##      unacc   3    0   299     0
##      vgood   0    1     0    13
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9722          
##                  95% CI : (0.9519, 0.9855)
##     No Information Rate : 0.7007          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9387          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: acc Class: good Class: unacc Class: vgood
## Sensitivity              0.9688     0.82353       0.9901      0.81250
## Specificity              0.9761     1.00000       0.9767      0.99759
## Pos Pred Value           0.9208     1.00000       0.9901      0.92857
## Neg Pred Value           0.9909     0.99281       0.9767      0.99281
## Prevalence               0.2227     0.03944       0.7007      0.03712
## Detection Rate           0.2158     0.03248       0.6937      0.03016
## Detection Prevalence     0.2343     0.03248       0.7007      0.03248
## Balanced Accuracy        0.9724     0.91176       0.9834      0.90505</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="random-forest.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(predModel2, car_test<span class="sc">$</span>Condition)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction acc good unacc vgood
##      acc    91    1     1     0
##      good    2   16     0     0
##      unacc   3    0   301     0
##      vgood   0    0     0    16
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9838          
##                  95% CI : (0.9668, 0.9934)
##     No Information Rate : 0.7007          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9643          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: acc Class: good Class: unacc Class: vgood
## Sensitivity              0.9479     0.94118       0.9967      1.00000
## Specificity              0.9940     0.99517       0.9767      1.00000
## Pos Pred Value           0.9785     0.88889       0.9901      1.00000
## Neg Pred Value           0.9852     0.99758       0.9921      1.00000
## Prevalence               0.2227     0.03944       0.7007      0.03712
## Detection Rate           0.2111     0.03712       0.6984      0.03712
## Detection Prevalence     0.2158     0.04176       0.7053      0.03712
## Balanced Accuracy        0.9710     0.96817       0.9867      1.00000</code></pre>
<p>This is backed up by the confusion matrix giving model 2 a higher accuracy than model 1</p>
<p>Now we know that a ntree = 500 and a mtry = 6 gives a higher, but what about all other posibilities? It’d be a lot of work to manually test for every single possibility, and determine the one with the highest accuracy.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="random-forest.html#cb128-1" aria-hidden="true" tabindex="-1"></a>x<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb128-2"><a href="random-forest.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>){</span>
<span id="cb128-3"><a href="random-forest.html#cb128-3" aria-hidden="true" tabindex="-1"></a>  Model3<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Condition <span class="sc">~</span> ., <span class="at">data=</span> car_train, <span class="at">ntree =</span> <span class="dv">500</span>, <span class="at">mtry =</span> i, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb128-4"><a href="random-forest.html#cb128-4" aria-hidden="true" tabindex="-1"></a>  PredictModel3<span class="ot">&lt;-</span><span class="fu">predict</span>(Model3, car_test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb128-5"><a href="random-forest.html#cb128-5" aria-hidden="true" tabindex="-1"></a>  x[i]<span class="ot">=</span><span class="fu">mean</span>(PredictModel3 <span class="sc">==</span> car_test<span class="sc">$</span>Condition)</span>
<span id="cb128-6"><a href="random-forest.html#cb128-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb128-7"><a href="random-forest.html#cb128-7" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">mtry=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,</span>
<span id="cb128-8"><a href="random-forest.html#cb128-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">prediction_power=</span>x)</span></code></pre></div>
<pre><code>##   mtry prediction_power
## 1    1        0.7935035
## 2    2        0.9698376
## 3    3        0.9791183
## 4    4        0.9814385
## 5    5        0.9791183
## 6    6        0.9860789</code></pre>
<p>Based on testing mtry’s 1-6 (6 being the maximum, since we only have 6 variables), we can conclude that a mtry = 6 does indeed give us the highest prediction power.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="random-forest.html#cb130-1" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb130-2"><a href="random-forest.html#cb130-2" aria-hidden="true" tabindex="-1"></a>range<span class="ot">&lt;-</span><span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">100</span>, <span class="at">to =</span> <span class="dv">1500</span>, <span class="at">by =</span> <span class="dv">100</span>)</span>
<span id="cb130-3"><a href="random-forest.html#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">100</span>, <span class="at">to =</span> <span class="dv">1500</span>, <span class="at">by =</span> <span class="dv">100</span>)){</span>
<span id="cb130-4"><a href="random-forest.html#cb130-4" aria-hidden="true" tabindex="-1"></a>  Model3<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Condition <span class="sc">~</span> ., <span class="at">data=</span> car_train, <span class="at">ntree =</span> i, <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb130-5"><a href="random-forest.html#cb130-5" aria-hidden="true" tabindex="-1"></a>  PredictModel3<span class="ot">&lt;-</span><span class="fu">predict</span>(Model3, car_test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb130-6"><a href="random-forest.html#cb130-6" aria-hidden="true" tabindex="-1"></a>  y[i]<span class="ot">=</span>(<span class="fu">mean</span>(PredictModel3 <span class="sc">==</span> car_test<span class="sc">$</span>Condition))</span>
<span id="cb130-7"><a href="random-forest.html#cb130-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb130-8"><a href="random-forest.html#cb130-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-9"><a href="random-forest.html#cb130-9" aria-hidden="true" tabindex="-1"></a>data<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">prediction_power=</span>y[range],</span>
<span id="cb130-10"><a href="random-forest.html#cb130-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">ntree=</span><span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">100</span>, <span class="at">to =</span> <span class="dv">1500</span>, <span class="at">by =</span> <span class="dv">100</span>))</span>
<span id="cb130-11"><a href="random-forest.html#cb130-11" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> <span class="fu">filter</span>(prediction_power<span class="sc">==</span><span class="fu">max</span>(y[range]))</span></code></pre></div>
<pre><code>##   prediction_power ntree
## 1        0.9860789   200
## 2        0.9860789   400
## 3        0.9860789   800</code></pre>
<p>Based on these results, we can see that 5 different ranges, 200, 400 and 800 all show the exact same (highest) prediction power. Thus, we can conclude in the 100’s range, there is no real big difference between different ntree amounts. Perhaps a logarithmic scale will show more difference?</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="random-forest.html#cb132-1" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb132-2"><a href="random-forest.html#cb132-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-3"><a href="random-forest.html#cb132-3" aria-hidden="true" tabindex="-1"></a>length<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">1</span> <span class="sc">%o%</span> <span class="dv">10</span><span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>))</span>
<span id="cb132-4"><a href="random-forest.html#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span> <span class="sc">%o%</span> <span class="dv">10</span><span class="sc">^</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>))){</span>
<span id="cb132-5"><a href="random-forest.html#cb132-5" aria-hidden="true" tabindex="-1"></a>  Model3<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Condition <span class="sc">~</span> ., <span class="at">data=</span> car_train, <span class="at">ntree =</span> i, <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb132-6"><a href="random-forest.html#cb132-6" aria-hidden="true" tabindex="-1"></a>  PredictModel3<span class="ot">&lt;-</span><span class="fu">predict</span>(Model3, car_test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb132-7"><a href="random-forest.html#cb132-7" aria-hidden="true" tabindex="-1"></a>  y[i]<span class="ot">=</span>(<span class="fu">mean</span>(PredictModel3 <span class="sc">==</span> car_test<span class="sc">$</span>Condition))</span>
<span id="cb132-8"><a href="random-forest.html#cb132-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb132-9"><a href="random-forest.html#cb132-9" aria-hidden="true" tabindex="-1"></a>data<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">prediction_power=</span>y[length],</span>
<span id="cb132-10"><a href="random-forest.html#cb132-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">ntree=</span>length)</span>
<span id="cb132-11"><a href="random-forest.html#cb132-11" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<pre><code>##   prediction_power ntree
## 1        0.9651972     1
## 2        0.9791183    10
## 3        0.9837587   100
## 4        0.9837587  1000
## 5        0.9837587 10000</code></pre>
<p>With this table, we <em>can</em> see that a ntree=1 has a lower predictive power, however, these differences are still quite small. Even still, they’re handy to keep in mind. Important to keep in mind is that any numbers in a higher power than 1.000 take significantly mote time to render. Thus, it’s the question of all that extra rendering time is worth an (in this case) insignificant difference.</p>
<p>With that, we’ve succesfully performed a randomForest analysis upon a “cars” dataset. Just like with the KNN, we’ll now perform the entire RandomForest workflow with the “Glass” dataset.</p>
<p>Now, we’ll look into a package for R called IDTAXA, which uses randomForest computation to identify bacteria based on their 16sRNA.</p>
<div>
<p><button class='button button1' onclick="window.location.href='pre-processing-karet.html#pre-processing-karet'" type="button">Return</button>
<button class='button button2' onclick="window.location.href='random-forest-in-glass.html#random-forest-in-glass'" type="button">Continue</button></p>
</div>

</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-duaUCIMachineLearning2017" class="csl-entry">
Dua, Dheeru, and Casey Graff. 2017. <span>“<span>UCI Machine Learning Repository</span>.”</span> <em>Machine Learning Repository</em>. https://archive.ics.uci.edu/ml/index.php.
</div>
</div>
<p style="text-align: center;">
<a href="pre-processing-karet.html"><button class="btn btn-default">Previous</button></a>
<a href="random-forest-in-glass.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
